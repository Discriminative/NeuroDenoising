<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Neuromorphic Imaging with Density-based Spatiotemporal Denoising</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Neuromorphic Imaging with Density-based Spatiotemporal Denoising</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">Transactions on Computational Imaging</span>
              <br>
              <!-- Paper authors -->
              <span class="author-block"><a href="https://scholar.google.com/citations?hl=en&user=Haaxgp0AAAAJ" target="_blank">Pei Zhang</a><sup>*</sup>,</span>
              <span class="author-block"><a href="https://scholar.google.com/citations?user=mR4sMzEAAAAJ&hl=en" target="_blank">Zhou Ge</a><sup>*</sup>,</span>
              <span class="author-block"><a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Li Song</a><sup>*</sup>,</span>
              <span class="author-block"><a href="https://www.eee.hku.hk/~elam/index.html" target="_blank">Edmund Y. Lam</a><sup>*</sup><sup>&#9768</sup>,</span>
            </div>
                  <div class="is-size-5 publication-authors">
                    <span class="eql-cntrb"><small><sup>*</sup>Department of Electrical and Electronic Engineering, The University of Hong Kong, Pokfulam, Hong Kong SAR, China.</small></span>
                    <span class="eql-cntrb"><small><br><sup>&#9768</sup>AI Chip Center for Emerging Smart Systems, Hong Kong Science Park, Hong Kong SAR, China.</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://discriminative.github.io/NeuroDenoising/" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper (coming soon)</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://discriminative.github.io/NeuroDenoising/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!== Your video here ==>
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3">ABSTRACT</h2>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="static/images/demo.png" alt="MY ALT TEXT" width="500" height="400"/>
        <br><br>
        <div class="content has-text-justified">
          <p>
            Bio-inspired neuromorphic cameras asynchronously record visual information of dynamic scenes by discrete events. 
            Due to the high sampling rate, they are capable of fast motion capture without causing image blur, overcoming the drawbacks of frame-based cameras that produce blurry recordings of dynamic objects. 
            However, highly sensitive neuromorphic cameras are also susceptible to interference, and can generate a lot of noise in response. 
            Such noisy event data can dramatically degrade the event-based observations and analysis. 
            Existing methods have insufficient performance on noise suppression, especially for the weak dynamic scenes where noise resembles signals in attributes and distribution, and their results thus have limited improvements on downstream applications. 
            Such demanding cases have not been fully investigated. We aim to seek a solution with more effective and robust discrimination between the two types of events, such that the denoised output can benefit neuromorphic classification tasks. 
            Therefore, we propose a sub-quadratic clustering algorithm tailored for neuromorphic data. 
            It couples event priors with density estimation for noise removal on raw event streams, where strongly correlated signals are taken to be denser in space-time. 
            Experiments on real and synthetic samples illustrate that our simple and interpretable algorithm can suppress noise significantly, and can show greater accuracy and robustness than other techniques in some challenging scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">EVALUATIONS</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <p class="subtitle">
          Denoising performance on the challenging scene, 
          where we use a blue box to mark the zone with the signals expected to be preserved and a red box for the one with the noise required to be removed.
        </p>
        <img src="static/images/results1.png" alt="MY ALT TEXT"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <p class="subtitle">
          We examine the denoising ability in two scenarios when the objects are recorded by fast-moving and slow-moving cameras. 
          Signals generated by the latter normally have a longer time interval similar to that of noise, which may confuse temporal-based mechanisms.
        </p>
        <img src="static/images/results2.png" alt="MY ALT TEXT"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <p class="subtitle">
          Effective denoising boosts classification accuracy on event data.
          We compare top-1 classification accuracy on the denoised events processed by each algorithm and find that the accuracy on noisy events decreases dramatically as the proportion of noise increases. 
          Our denoised events achieve better improvements than other counterparts.
        </p>
        <img src="static/images/results3.png" alt="MY ALT TEXT"/>
     </div>
     <div class="item">
      <!-- Your image here -->
      <p class="subtitle">
        We use &#951 as another independent evaluation. The comparisons present higher values of &#951 with our method for most test cases.
      </p>
      <img src="static/images/results4.png" alt="MY ALT TEXT"/>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!== Paper video. ==>
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!== Youtube embed code here ==>
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!== Your video file here ==>
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!== Your video file here ==>
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!== Your video file here ==>
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content footersize">
          <p>
            This page is based on the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>. 
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
